# UNet

## Abstract

深度网络的成功训练需要数千个带注释的训练样本，这一点得到了广泛的认同。在本文中，我们提出了一个网络和训练策略，它依赖于强大的**数据增强**的使用，以更有效地使用可用的注释样本。该体系结构由一个用于**捕获上下文的收缩路径（encoder）**和一个**支持精确定位的对称扩展路径（decoder）**组成。我们表明，这样的网络可以从很少的图像实现端到端训练，并且在电子显微镜堆栈中分割神经元结构的ISBI挑战上优于先前的最佳方法(滑动窗口卷积网络)。使用在透射光显微镜图像(相位对比和DIC)上训练的相同网络，我们在这些类别中以很大的优势赢得了2015年的ISBI单元跟踪挑战。此外，网络是快速的。在最近的GPU上分割512x512图像需要不到一秒钟。

## 1. Introduction

卷积网络的典型用途是分类任务，其中图像的输出是单个类别标签。然而，在许多视觉任务中，尤其是在生物医学图像处理中，期望的输出应该包括定位，即，应该为每个像素分配一个类别标签。此外，在生物医学任务中，通常很难拿到数千张训练图像。因此Ciresan等人再滑动窗口设置中训练了一个网络，可以通过提供像素周围的局部区域（patch）作为输入来预测每个像素的类别标签。首先，这个网络有定位功能。其次，以patches表示的训练数据要远远大于训练图像的数量，起到了数据增强的作用。

显然，Ciresan等人的方法两个缺点。首先，他的速度相当慢，因为网络必须为每个patches单独运行，并且由于patches重叠而会存在大量冗余。其次，在定位精度和上下文使用直接存在权衡，大的patches需要更多的max-pooling层，这回降低localize的精度，而小的patches使得网络只能看到很少的上下文。最近的方法[11, 4]提出了一种分类器输出，该输出考虑了来自多个层的特征，可以同时很好地实现localization和context上下文。

在本文中，我们构建了一个更优雅的体系结构，即所谓的“全卷积网络”[Fully Connected Network]。我们修改和扩展了这个架构，这样它可以在很少的训练图像和产生更精确的分割;参见图1。[FCN]的主要思想是用连续的层来补充通常的收缩网络，其中池化算子被上采样算子取代。因此，这些层增加了输出的分辨率。为了定位，将收缩路径（encoder）的高分辨率特征与上采样输出（decoder）相结合（跳跃连接）,然后，一个连续的卷积层可以学习基于这个信息组装一个更精确的输出。然后，一个连续的卷积层可以学习基于这个信息组装一个更精确的输出。

我们架构中的一个重要修改是：在上采样部分，我们也有大量的特征通道，这允许网络将上下文信息传播到更高分辨率的层。因此，扩展路径（decoder）几乎和收缩路径（encoder）对称，并形成U型结构。该网络没有任何全连接层，只使用每个卷积的有效部分，即segmentation map只包含像素点，对于这些像素点，输入图像中有完整的上下文。该策略允许通过重叠策略对任意大的图像进行无缝分割(见图2)。为了预测图像边界区域的像素，缺失的上下文是通过镜像输入图像来推断的。这种平铺策略对于将网络应用于大型图像非常重要，因为否则分辨率将受到GPU内存的限制。

**滑动窗口**方法：在滑动窗口中训练一个网络，通过提供像素周围的局部区域（补丁）作为输入来预测每个像素的类别标签；优点：网络能够定位，且在patches部分的训练数据远大于训练图像个数（相当于扩增了数据集）。缺点：由于要分别关注每个patch，网络速度非常慢并且在重叠的patch上会存在冗余；在定位准确性和语境（context）使用之间存在权衡：更大的patch需要更多的最大池化层，这使得定位精确度降低，然而小的patch允许网络只看到很少的context

## 2. Network Architecture

![image-20220302101143546](C:%5CUsers%5CBreeze%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20220302101143546.png)

**`Unet`不是左右对称！**

overlap-tile [【图像处理】U-Net中的重叠-切片(Overlap-tile) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/281404684)

contracting path

> 2个3x3conv  RELU  2x2maxpooling  double channels

expansive path 

> up-conv halve channels concatenation  
>
> S2个3x3conv RELU

使用加权损失，背景标签会获得较大的权重

边界采用镜像填充

采用弹性形变来进行数据增强，因为在实际的医疗情景中变形的目标是很常见的

当时，Unet相比更早提出的FCN网络，使用**拼接**来作为特征图的融合方式。

- FCN是通过特征图对应像素值的相加来融合特征的；
- U-net通过通道数的拼接，这样可以形成更厚的特征，当然这样会更佳消耗显存；

**Unet的好处我感觉是：网络层越深得到的特征图，有着更大的视野域，浅层卷积关注纹理特征，深层网络关注本质的那种特征，所以深层浅层特征都是有各自的意义的；另外一点是通过反卷积得到的更大的尺寸的特征图的边缘，是缺少信息的，毕竟每一次下采样提炼特征的同时，也必然会损失一些边缘特征，而失去的特征并不能从上采样中找回，因此通过特征的拼接，来实现边缘特征的一个找回。**

Unet在医疗影像中效果好的原因：

1. 医疗影像语义较为简单、结构固定。因此语义信息相比自动驾驶等较为单一，因此并不需要去筛选过滤无用的信息。**医疗影像的所有特征都很重要，因此低级特征和高级语义特征都很重要，所以U型结构的skip connection结构（特征拼接）更好派上用场**
2. 医学影像的数据较少，获取难度大，数据量可能只有几百甚至不到100，因此如果使用大型的网络例如DeepLabv3+等模型，很容易过拟合。大型网络的优点是更强的图像表述能力，而较为简单、数量少的医学影像并没有那么多的内容需要表述，因此也有人发现**在小数量级中，分割的SOTA模型与轻量的Unet并没有神恶魔优势**

## Training

为了最小化开销并最大限度地利用GPU内存，我们更喜欢大的输入块而不是大的批处理大小，从而将**批处理减少到单个图像**

使用SGD，**高动量(0.99)**，这样，大量之前看到的训练样本决定了当前优化步骤中的更新。

### 能量函数（Loss）

cross entropy：

![image-20220302112514305](C:%5CUsers%5CBreeze%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20220302112514305.png)

:star:其中w是权重，我们将预先计算每个ground truth segmentation 的权值图，以补偿训练数据集中某类像素的不同频率, weighted map可按如下公式计算

![image-20220302113004991](C:%5CUsers%5CBreeze%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20220302113004991.png)

d1：the distance to the border of the nearest cell

d2：the distance to the border of the second nearest cell

set w0 = 10, sigma = 5

### 权重初始化

:star:对于UNet的网络（交替卷积和ReLU），可以通过从标准偏差为`sqr(2/N)`的高斯分布中绘制初始权值来实现，其中N表示一个神经元的传入节点数。例如，对于前一层的3x3卷积和64个特征通道N = 9·64 =  576。

注：此方法来自[Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.pdf (arxiv.org)](https://arxiv.org/pdf/1502.01852.pdf)