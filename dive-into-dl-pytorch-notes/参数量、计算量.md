## 1、参数量

简化算法：

![img](https://img-blog.csdnimg.cn/20210812215927915.png)

**1.1 卷积网络**

假设卷积核的大小为 k*k, 输入channel为M， 输出channel为N。

（1）bias为True时：

则参数数量为：k×k×M×N + N（bias的数量与输出channel的数量是一样的）

（2）bias为False时：

则参数数量为：k×k×M×N

（3）当使用BN时，还有两个可学习的参数α和β，参数量均为N

则参数数量为：k×k×M×N + 2×N

**1.2 全连接层**

假设 输入神经元数为M，输出神经元数为N，则

（1）bias为True时：

则参数数量为：M*N + N（bias的数量与输出神经元数的数量是一样的）

（2）bias为False时：

则参数数量为：M×N

## 2、计算量

计算量(FLOPs)对应时间复杂度

简化算法：

![img](https://img-blog.csdnimg.cn/20210812215850725.png)

李沐上课说的是用上面的公式:arrow_up: 但是下面这个算法好像也挺有道理

**2.1 卷积**

假设输入特征图（B，C，H，W），卷积核大小为K×K， 输入通道为C，输出通道为N，步长stride为S， 输出特征图大小为H2，W2.

（1）一次卷积的计算量

一个k×k的卷积，执行一次卷积操作，需要**k×k次乘法**操作（卷积核中每个参数都要和特征图上的元素相乘一次），**k×k−1 次加法**操作（将卷积结果，k×k 个数加起来）。所以，一次卷积操作需要的乘加次数：(K×K)+(K×K−1)=2×K×K−1

（2）在一个特征图上需要执行卷积需要卷积的次数

在一个特征图上需要执行的**卷积次数**：(（H-k+Ph）/S +1 )×(（H-k+Pw）/S +1)，Ph，Pw表示在高和宽方向填充的像素，此处假定了宽高方向滑动步长和核的宽高是一样，若不同，调整一下值即可。若不能整除，可向下取整。

（3）C个特征图上进行卷积运算的次数

C个输入特征图上进行卷积运算的次数为C

（4）输出一个特征图通道需要的加法次数

在C个输入特征图上进行卷积之后需要将卷积的结果相加，得到一个输出特征图上卷积结果，C个相加需要C-1次加法，计算量为 ：（C-1）×H2×W2

（5）输出N个特征图需要计算的次数

`N×((C-1)×H2×W2 + (2×K×K − 1)×((H-k+Ph)/S + 1)×((H-k+Pw)/S + 1) ×C)`
（6）一个batch需要计算的次数

`B×N×((C-1)×H2×W2 + (2×K×K − 1)×((H-k+Ph)/S + 1)×((H-k+Pw)/S + 1) × C)`

**2.1 全连接**

假设 输入神经元数为M，输出神经元数为N，则

（1）先执行M次乘法；

（2）再执行M-1次加法

（3）加上bias，计算出一个神经元的计算量为 （M+M-1+1）

（4）N个输出神经元，则总的计算量为 2M×N