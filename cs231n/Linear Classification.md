---

typora-root-url: images
---

## Linear Classification

### Parameterized mapping from images to label scores

寻找一个函数将图片的像素值映射到每一类别对应的置信度。

线性分类器：一个最简单的线性映射$f(x_i,W,b)=Wx_i +b$ 

使用矩阵乘法可以加快计算速度，目标时使得预测标签尽可能接近真实标签，记录下来的权重值在推理预测时可以直接使用所以大大加快了预测的速度。

### Interpreting a linear classifier

注意线性分类器计算的是所有三个颜色通道的加权，可见如果是轮船分类器，那么蓝色通道的权重将会较大。

**Analogy of images as high-dimensional points.**

> 将每张图片等价为3072维的空间，简化为二维平面上的点，此时的图片分类也就是一个线性分类器。

**Interpretation of linear classifiers as template matching.** 

> 可以看作是在做模板匹配，权重W的每一行表示类别之中的模板，可以通过点积或是内积来找到一个最匹配的类别score，其实也有点像是Nearest Neighbor，但不同的是不需要每次都和几千张训练数据进行比较L1、L2距离，而是用权重记录下来。

**Bias trick**

![image-20220505103120286](/image-20220505103120286.png)

通过在将bias加入到W矩阵中，$x_i$ 多加一项常数1，可以简化学习参数，只要学习一个权重矩阵即可。

**Image data preprocessing.** 

在机器学习中，我们通常会将输入特征进行归一化处理，计算出数据集中图像的均值，然后将每张图片减去均值，使得像素值范围在[-127，127]，更进一步的处理可以放缩到[-1, 1]

### Loss function

#### Multiclass Support Vector Machine loss

SVM的损失函数想要SVM在正确分类上的得分始终比不正确分类上的得分高出一个边界值![[公式]](/equation.svg)。

![[公式]](/equation-1651721939271.svg)

简而言之，SVM的损失函数想要正确分类类别![[公式]](/equation-1651722072171.svg)的分数比不正确类别分数高，而且至少要高![[公式]](/equation-1651722072290.svg)。如果不满足这点，就开始计算损失值。

那么在这次的模型中，我们面对的是线性评分函数（![[公式]](/equation-1651722106823.svg)），所以我们可以将损失函数的公式稍微改写一下：

![[公式]](/equation-1651722106856.svg)

在结束这一小节前，还必须提一下的以0为阀值的函数：![[公式]](/equation-1651722196451.svg)函数，它常被称为**折叶损失（hinge loss）**。有时候会听到人们使用平方折叶损失SVM（即L2-SVM），它使用的是![[公式]](/equation-1651722196472.svg)，将更强烈（平方地而不是线性地）地惩罚过界的边界值。不使用平方是更标准的版本，但是在某些数据集中，平方折叶损失会工作得更好。可以通过交叉验证来决定到底使用哪个。

**Regularization**

使用以上损失函数可能存在一个bug：当初是权重和数据恰好拟合的时候，得到的损失值可能是0。

在损失函数中增加正则损失项（常用L2损失）可以使得SVM具有最大边界的性质

鼓励分类器最终将所有维度上的特征都用起来，而不是强烈依赖其中少数几个维度。这一效果将会提升分类器的泛化能力，并避免过拟合。注意这里正则项是关于权重矩阵的，与数据无关。$R(W) = \sum_k \sum_l W_{k,l} ^2$

需要注意的是，和权重不同，偏差bias没有这样的效果，因为它们并不控制输入维度上的影响强度，因此不对bias进行正则化。